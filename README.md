
# ğŸ›’ ShopNow E-Commerce - Capstone Project

ShopNow is a **Kubernetes learning project** built around a full-stack MERN e-commerce application:
- **Customer App** (React frontend)  
- **Admin Dashboard** (React admin panel)  
- **Backend API** (Express + MongoDB)  

This project teaches **Kubernetes** from container basics to production-ready deployments with Dockerfiles, Kubernetes manifests, Helm, GitOps and CICD using Jenkins.

## ğŸ¯ Learning Objectives
- Write Dockerfiles for containerising the application
- Write Kubernetes manifest files for container orchestration
- Understand and implement HELM Chart for application deployment on kubernetes
- Implement GitOps workflows using ArgoCD
- Implement CICD pipelines using Jenkins

---

## ğŸ“ Project Structure

```
shopNow/
â”œâ”€â”€ backend/               # Node.js API server
â”œâ”€â”€ frontend/              # React customer app
â”œâ”€â”€ admin/                 # React admin dashboard
â”œâ”€â”€ kubernetes
â”‚   â”œâ”€â”€ k8s-manifests/     # Raw Kubernetes YAML files
â”‚   â”œâ”€â”€ helm/              # Helm charts for package management
â”‚   â”‚   â””â”€â”€ charts/        # Individual charts
â”‚   â”œâ”€â”€ argocd/            # GitOps deployment configs
â”‚   â””â”€â”€ pre-req/           # Cluster prerequisites
â”œâ”€â”€ jenkins/               # Pipeline definitions (CI & CD)       
â”œâ”€â”€ docs/                  # learning resources and guides
â””â”€â”€ scripts/               # Automation and utility scripts
```

---

## ğŸš€ Learning Journey

### Container & Kubernetes Basics
1. **Start Here**: [docs/K8S-CONCEPTS.md](docs/K8S-CONCEPTS.md) - Core concepts explained
2. **Raw Kubernetes Manifests**: `kubernetes/k8s-manifests/`

### Package Management & Automation  
3. **Helm Charts**: `kubernetes/helm/`
4. **CI/CD Pipelines**: `jenkins/`

### GitOps & Production Readiness
5. **ArgoCD GitOps**: `kubernetes/argocd/`


## Getting Started

## ğŸ›  Prerequisites & Setup

#### 1. Setup Tools**: [docs/TOOLS-SETUP-GUIDE.md](docs/TOOLS-SETUP-GUIDE.md)

#### 2. AWS ECR Registry Setup 
```bash
# Setup AWS credentials first
aws configure
# Enter your AWS Access Key ID, Secret Access Key, region (us-east-1), and output format (json)

# Or use environment variables
export AWS_ACCESS_KEY_ID=your-access-key
export AWS_SECRET_ACCESS_KEY=your-secret-key
export AWS_DEFAULT_REGION=ca-central-1

# If above credentials are already set, run below command to verify
aws sts get-caller-identity

# Create ECR repositories either via the aws cli as mentioned below or via console (Has to be done once to create the ECR repo, skip this step when you are rebuilding the docker images):

like:

aws ecr create-repository --repository-name <your-username>-shopnow/frontend --region <region>
aws ecr create-repository --repository-name <your-username>-shopnow/backend --region <region>
aws ecr create-repository --repository-name <your-username>-shopnow/admin --region <region>

# Get login token (run this command everytime as the docker credentials are persisted only on the terminal)
aws ecr get-login-password --region <region> | docker login --username AWS --password-stdin <account-id>.dkr.ecr.<region>.amazonaws.com
```

#### 3. Kubernetes Cluster Access (Make sure to have a running Kubernetes cluster, here is an example to connect with EKS)
```bash
# For EKS cluster
aws eks update-kubeconfig --region <region> --name <your-cluster-name>

# Verify access
kubectl cluster-info
kubectl get nodes
```

Note: All the below mentioned kubectl commands assume that you are working with "aviral-k8" namespace, update the namespace as per yours where ever you find "aviral-k8".

#### 4. Docker Registry Secret

```bash
# Create registry secret for private ECR image pulls
kubectl create ns aviral-k8
kubectl create secret docker-registry ecr-secret --docker-server=<account-id>.dkr.ecr.ca-central-1.amazonaws.com --docker-username=AWS --docker-password=$(aws ecr get-login-password --region ca-central-1) --namespace=aviral-k8
```

#### 5. Install Pre-requisites in the Kubernetes Environment (Has to be done once per Kubernetes Cluster)
```bash
# Install metrics server (required for resource monitoring and HPA)
kubectl apply -f kubernetes/pre-req/metrics-server.yaml

# Install ingress-nginx controller (for external access)
# For EKS, other cloud provider will have different file
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.12.0-beta.0/deploy/static/provider/aws/deploy.yaml

# For local development (minikube/kind/Docker Desktop)
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.1/deploy/static/provider/kind/deploy.yaml

# Verify installations
kubectl get pods -n kube-system
kubectl get pods -n ingress-nginx
kubectl top nodes  # Should work after metrics server is running
kubectl top pods  # Should work after metrics server is running

# To enable Persistent Storage

# First install the EBS CSI driver as an EKS Addon

-> In the EKS Console, open your cluster â†’ go to Add-ons â†’ click Get more add-ons â†’ select Amazon EBS CSI driver â†’ click Next.
-> On the configuration page, Under Pod identity association, choose Create a new IAM role, and the console will auto-attach the AmazonEBSCSIDriverPolicy.
-> Confirm and click Create. The add-on installs, the IAM role is associated with the SA via Pod Identity, and the driver starts running.
-> Verify under Add-ons tab that the EBS CSI driver is active and under Pod identity associations tab you see the SA <-> IAM role mapping.

# Install storage class for persistent volumes
kubectl apply -f kubernetes/pre-req/storageclass-gp3.yaml

# Verify storage class installation
kubectl get storageclass


```


## âš¡ Build and Deploy the micro-services

### 1. Build the docker images and push it to the ECR registry created above

```bash
scripts/build-and-push.sh <account-id>.dkr.ecr.<region>.amazonaws.com/<registry-name> <tag-name-number> <your-username> 

# Example for user 'aviral' with tag 'latest' and ECR registry '975050024946.dkr.ecr.ca-central-1.amazonaws.com/shopnow':
./scripts/build-and-push.sh 975050024946.dkr.ecr.ca-central-1.amazonaws.com/shopnow latest aviral


```

### 2. Choose Your Deployment Method

**Option A: Raw Kubernetes Manifests**
```bash
kubectl apply -f kubernetes/k8s-manifests/namespace/
kubectl apply -f kubernetes/k8s-manifests/database/
kubectl apply -f kubernetes/k8s-manifests/backend/
kubectl apply -f kubernetes/k8s-manifests/frontend/
kubectl apply -f kubernetes/k8s-manifests/admin/
kubectl apply -f kubernetes/k8s-manifests/ingress/
kubectl apply -f kubernetes/k8s-manifests/daemonsets-example/
```

**Option B: Helm Charts**

```bash
helm upgrade --install mongo kubernetes/helm/charts/mongo -n aviral-k8 --create-namespace
helm upgrade --install backend kubernetes/helm/charts/backend -n aviral-k8
helm upgrade --install frontend kubernetes/helm/charts/frontend -n aviral-k8
helm upgrade --install admin kubernetes/helm/charts/admin -n aviral-k8
```

**Option C: ArgoCD GitOps**
```bash
# Install ArgoCD first
kubectl create namespace argocd
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

# Create target namespace
kubectl create namespace aviral-k8

# Deploy applications
kubectl apply -f kubernetes/argocd/umbrella-application.yaml

# Check all ArgoCD application status:
kubectl get applications -n argocd

```

### 3. Create users in MongoDB after the mongodb pods are healthy

```bash

# check the status of the mongo-0 pods 
kubectl get pods -n aviral-k8

# if mongo-0 pod is healthy, then run following command to create a user for the backend to connect
# user credentials should be same as mentioned in the backend secrets-db.yaml file
# First exex into the pods
kubectl -n aviral-k8 exec -it mongo-0 -- mongosh

# Run below commands
use admin;
db.createUser({
  user: 'shopuser',
  pwd: 'ShopNowPass123',
  roles: [
    { role: 'readWrite', db: 'shopnow' },
    { role: 'dbAdmin', db: 'shopnow' }
  ]
});

exit

# Restart backend deployment
kubectl rollout restart deploy backend -n aviral-k8
```

### 4. Check the resources deployed

```bash
# Check Pods
kubectl get pods -n aviral-k8

# Check Deployment
kubectl get deploy -n aviral-k8

# Check Services
kubectl get svc -n aviral-k8

# Check daemonsets
kubectl get daemonsets -n aviral-k8

# Check statefulsets
kubectl get statefulsets -n aviral-k8

# Check HPA
kubectl get hpa -n aviral-k8

# Check all of the above at once
kubectl get all -n aviral-k8

# Check configmaps
kubectl get cm -n aviral-k8

# Check secrets
kubectl get secrets -n aviral-k8

# Check ingress
kubectl get ing -n aviral-k8

# Sequence to debug in case of any issue with the pods
kubectl get pods -n aviral-k8
kubectl describe pod backend-746cc99cd-cqrgf -n aviral-k8 # Assuming that pod backend-746cc99cd-cqrgf has an error
kubectl logs backend-746cc99cd-cqrgf -n aviral-k8 --previous # If no details are found in the above command or if details like liveness probe failed are coming

```


---

## Screenshots
![AWS Configure](Screenshots/awsconfigure.png)
![Cluster Info](Screenshots/clusterinfo.png)
![Namespace and Secret](Screenshots/nsanddockersecret.png)
![Pods Info](Screenshots/podsinfo.png)
![Service and Ingress Info](Screenshots/serviceinfo.png)

---

## Additional Notes

**Check the Application Architecture details**: [docs/APPLICATION-ARCHITECTURE.md](docs/APPLICATION-ARCHITECTURE.md)
**Check the Troubleshooting Guide**: [docs/TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md)
---

## ğŸ‘¨â€ğŸ’» Author
 forked from aryanm12/shopNow

## Capstone Members
- Aviral Paliwal
- Aishwarya Patil
- Sanidhya Gadgil
- Munit
---
